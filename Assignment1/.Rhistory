print(paste("Avg","&", format(round(accuracy,3),3) ,"&" ,  format(round(precision,3),3) , "&", format(round(recall,3),3) ,"&" , format(round(TP_Rate,3),3) ,"&", format(round(FP_Rate,3),3) ,"&", format(round(F1,3),3)))
library("party")
library("rpart")
source("config.R")
source("missing_attributes.R")
#Try cross validation using http://machinelearningmastery.com/how-to-estimate-model-accuracy-in-r-using-the-caret-package/
#Handle missing values
mydata = read.csv("pima-indians-diabetes.data.txt",header = FALSE)
#Giving attribute names to imported data
colnames(mydata) = c("Num_Preg","PGC","BP","Tricept_Thickness","Insulin","BMI","DPF","Age","Label")
rows = length(mydata[[1]])
set.seed(2) #Setting a seed for deterministic evaluation
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#flds has the five indices set in it.
i = 1 #Setting a general default value
accuracy = 0
precision = 0
recall = 0
TP_Rate = 0
FP_Rate = 0
F1 = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
#fixing missing values
test = fix_missing_attributes(test , Missing_Attribute_Test)
train = fix_missing_attributes(train , Missing_Attribute_Train)
#Making and posting the decision tree
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control()) #Asuuming the . means all the other columns
post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
prediction = predict(decision_tree , test , type = "class")
actual = test[[9]]
TP = length(which(prediction == 1 & actual == 1))
FP = length(which(prediction == 1 & actual == 0))
FN = length(which(prediction == 0 & actual == 1))
TN = length(which(prediction == 0 & actual == 0))
P = TP + FN
N = FP + TN
print(paste("CV",i,"&", format(round((TP + TN )/(P+N),3),3) ,"&" ,  format(round(TP/(TP + FP),3),3) , "&", format(round(TP/(TP + FN),3),3) ,"&" , format(round(TP/P,3),3) ,"&", format(round(FP/N,3),3) ,"&", format(round(2*TP/(2*TP + FP + FN),3),3)))
accuracy = accuracy +   (TP + TN )/(P+N)
precision = precision + TP/(TP + FP)
recall = recall + TP/(TP + FN)
TP_Rate = TP_Rate + TP/P
FP_Rate = FP_Rate + FP/N
F1 = F1 + 2*TP/(2*TP + FP + FN)
}
print(paste("Avg","&", format(round(accuracy,3),3) ,"&" ,  format(round(precision,3),3) , "&", format(round(recall,3),3) ,"&" , format(round(TP_Rate,3),3) ,"&", format(round(FP_Rate,3),3) ,"&", format(round(F1,3),3)))
print(paste("Avg","&", format(round(accuracy/5,3),3) ,"&" ,  format(round(precision/5,3),3) , "&", format(round(recall/5,3),3) ,"&" , format(round(TP_Rate/5,3),3) ,"&", format(round(FP_Rate/5,3),3) ,"&", format(round(F1/5,3),3)))
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control()) #Asuuming the . means all the other columns
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R")
F1 = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
#fixing missing values
test = fix_missing_attributes(test , Missing_Attribute_Test)
train = fix_missing_attributes(train , Missing_Attribute_Train)
#Making and posting the decision tree
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control()) #Asuuming the . means all the other columns
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R")
}
#Overall Results
?rpart
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
printcp(decision_tree)
decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
library("party")
library("rpart")
source("config.R")
source("missing_attributes.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
#fixing missing values
test = fix_missing_attributes(test , Missing_Attribute_Test)
train = fix_missing_attributes(train , Missing_Attribute_Train)
source("tree.R")
source("compute.R") #Added computations to another file to avaoid confusion
}
#Overall Results
print(paste("Avg","&", format(round(accuracy/5,3),3) ,"&" ,  format(round(precision/5,3),3) , "&", format(round(recall/5,3),3) ,"&" , format(round(TP_Rate/5,3),3) ,"&", format(round(FP_Rate/5,3),3) ,"&", format(round(F1/5,3),3)))
plotcp(fit)
?rpart.control
library("party")
library("rpart")
source("config.R")
source("missing_attributes.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
#fixing missing values
test = fix_missing_attributes(test , Missing_Attribute_Test)
test = fix_missing_attributes(test , Missing_Attribute_Test)
train = fix_missing_attributes(train , Missing_Attribute_Train)
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
plotcp(fit)  #To isualise the error with respect to cp
decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
i
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , "\\ \hline"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , "\\\\ \\hline"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , "\\ \hline"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , "\\ \hline"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , "\\ \\hline"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , @"\\ \hline"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , '\\ \hline'))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score" , "\\ \hline"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score"))
print(paste("Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score"))
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
print(paste("{\bf","Data" , "&" ,  "accuracy" ,"&" ,  "precision" , "&", "recall" ,"&" , "TP Rate" ,"&", "FP Rate" ,"&", "F1 Score"))
print(paste("{\bf","Data" ,"}", "&" ,{\bf",  "accuracy","}" ,"&" ,{\bf",  "precision" ,"}", "&",{\bf", "recall" ,"}","&" ,{\bf", "TP Rate" ,"}","&", {\bf","FP Rate" ,"}","&", {\bf","F1 Score","}"))
print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
print(paste("{\bf","Avgerage","}","&", "{\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
source('~/.active-rstudio-document')
(data[,2:8]
)
data[data[9] == 1][,2:8]
data[data[9] == 1]
data[9]
data[9] == 1
data[[data[9] == 1] , ]
data[[[data[9] == 1]] , ]
data[1 , ]
data[1:3 , ]
data[[data[9] == 1] , ]
data[[data[9] == 1] ]
data[data$V9 == 1]
data[data$V9 == 1]
data[data$V9 = 1]
data[data$V9 == 1,]
data[data$V9 == 1,][,2:8]
data[data$V9 == 1,][,2:8] <- apply(data[data$V9 == 1,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
data[data$V9 == 0,][,2:8] <- apply(data[data$V9 == 0,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
?seq
cv_list = seq(0 , 0.025 , 0.001)
cv_list
vec <- numeric(10)
vec
length(cv_list)
vec[1]
vec[1] <- 1
vec
cv_list[1] <- 1
cv_list
cv_list = seq(0 , 0.025 , 0.001)
average_accuracy = numeric(length(cv_list))
for (j in 1:length(cv_list)){
accuracy = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
#fixing missing values
test = fix_missing_attributes(test , Missing_Attribute_Test)
train = fix_missing_attributes(train , Missing_Attribute_Train)
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
#plotcp(fit)  #To isualise the error with respect to cp
decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
average_accuracy[i] <- accuracy/5
}
#Overall Results
#print(paste("{\bf","Average","}","&", "{\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
average_accuracy
cp_list = seq(0 , 0.025 , 0.001)
average_accuracy = numeric(length(cv_list))
for (j in 1:length(cv_list)){
accuracy = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
#fixing missing values
test = fix_missing_attributes(test , Missing_Attribute_Test)
train = fix_missing_attributes(train , Missing_Attribute_Train)
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
#plotcp(fit)  #To isualise the error with respect to cp
decision_tree <- prune(fit , cp = cp_list[j])
#decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
average_accuracy[i] <- accuracy/5
}
#Overall Results
#print(paste("{\bf","Average","}","&", "{\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
average_accuracy
for (j in 1:length(cv_list)){
accuracy = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
#fixing missing values
test = fix_missing_attributes(test , Missing_Attribute_Test)
train = fix_missing_attributes(train , Missing_Attribute_Train)
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
#plotcp(fit)  #To isualise the error with respect to cp
decision_tree <- prune(fit , cp = cp_list[j])
#decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
average_accuracy[j] <- accuracy/5
}
average_accuracy
?plot.rpart
plot(cp_list , average_accuracy)
colMeans
train[2]
test[test$V9 == 1,][i]
test[test$V9 == 1,]
test
test[test$V9 == 1,]
test[test$V9 == 1,][1]
test[test$V9 == 1,][,]
train[train$V9 == 1,][,2:8]
train
train[train$V9 == 1,][,2:8]
train[[train$V9 == 1],][,2:8]
train[train$V9 == 1,][,2:8] <- apply(train[train$V9 == 1,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
train[train$V9 == 0,][,2:8] <- apply(train[train$V9 == 0,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
test
train[[train$Label == 1],][,2:8]
train[train$Label == 1,][,2:8]
test[test$Label == 1,][i] <- training_avg_Values1[i]
train[train$Label == 1,][,2:8] <- apply(train[train$Label == 1,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
train[train$Label == 0,][,2:8] <- apply(train[train$Label == 0,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
training_avg_Values1 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
training_avg_values0 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
for i in (2:8){
for (i in 2:8){
#Replace test missing data with train data means
test[test$Label == 1,][i] <- training_avg_Values1[i]
test[test$Label == 0,][i] <- training_avg_Value0[i]
}
training_avg_Values1 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
training_avg_Values0 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
for (i in 2:8){
#Replace test missing data with train data means
test[test$Label == 1,][i] <- training_avg_Values1[i]
test[test$Label == 0,][i] <- training_avg_Value0[i]
}
test[test$Label == 0,][i] <- training_avg_Values0[i]
else if (type == "UseMean"){
#Replacing missing values by class means
train[train$Label == 1,][,2:8] <- apply(train[train$Label == 1,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
train[train$Label == 0,][,2:8] <- apply(train[train$Label == 0,][,2:8] , 2 , function(x) {x[x==0] <- mean(x,na.rm = TRUE); x})
training_avg_Values1 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
training_avg_Values0 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
for (i in 2:8){
#Replace test missing data with train data means
test[test$Label == 1,][i] <- training_avg_Values1[i]
test[test$Label == 0,][i] <- training_avg_Values0[i]
}
test
test[test$Label == 1,][i]
test[test$Label == 1,][i] == 0
test[test$Label == 1,][i][  test[test$Label == 1,][i] == 0]
test[test$Label == 1,][i][  test[test$Label == 1,][i] == 36.67873]
test[test$Label == 1,][i][  test[test$Label == 1,][i] >30]
library("party")
library("rpart")
source("config.R")
source("missing_attributes.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0 , 0.025 , 0.001)
average_accuracy = numeric(length(cv_list))
for (j in 1:length(cv_list)){
accuracy = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
source("missing_attributes.R")
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
#plotcp(fit)  #To isualise the error with respect to cp
decision_tree <- prune(fit , cp = cp_list[j])
#decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
average_accuracy[j] <- accuracy/5
}
#Overall Results
#print(paste("{\bf","Average","}","&", "{\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
source("missing_attributes.R")
source("missing_attributes.R")
source("missing_attributes.R")
test
train
test
library("party")
library("rpart")
source("config.R")
source("missing_attributes.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0 , 0.025 , 0.001)
average_accuracy = numeric(length(cv_list))
#for (j in 1:length(cv_list)){
#   accuracy = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
source("missing_attributes.R")
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
#plotcp(fit)  #To isualise the error with respect to cp
#decision_tree <- prune(fit , cp = cp_list[j])
decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
average_accuracy[j] <- accuracy/5
#}
#Overall Results
print(paste("{\bf","Average","}","&", "{\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
source('~/Desktop/Academics/MLT/Assignment1/config.R')
source('~/Desktop/Academics/MLT/Assignment1/config.R')
source('~/Desktop/Academics/MLT/Assignment1/config.R')
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
source('~/Desktop/Academics/MLT/Assignment1/config.R')
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
source('~/Desktop/Academics/MLT/Assignment1/Pruning.R')
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
test[test$Label == 1,][i][test[test$Label == 1,i] == 0] <- training_avg_Values1[i]
test
for (i in 2:8){
#Replace test missing data with train data means
test[test$Label == 1,][i][test[test$Label == 1,i] == 0] <- training_avg_Values1[i]
test[test$Label == 0,][i][test[test$Label == 1,i] == 0] <- training_avg_Values0[i]
}
source("Pruning.R")
source("Pruning.R")
test
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0 , 0.025 , 0.001)
source("config.R")
source("missing_attributes.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0 , 0.025 , 0.001)
average_accuracy = numeric(length(cv_list))
#for (j in 1:length(cv_list)){
#   accuracy = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
source("missing_attributes.R")
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
#plotcp(fit)  #To isualise the error with respect to cp
#decision_tree <- prune(fit , cp = cp_list[j])
decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
average_accuracy[j] <- accuracy/5
#}
#Overall Results
print(paste("I =", Impurity_Function , "MATr =", Missing_Attribute_Train , "MATe =", Missing_Attribute_Test , "{\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
library("party")
library("rpart")
source("config.R")
source("missing_attributes.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0 , 0.025 , 0.001)
source("config.R")
test
train
training_avg_Values1 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
training_avg_Values0 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
for (i in 2:8){
#Replace test missing data with train data means
test[test$Label == 1,][i][test[test$Label == 1,i] == 0] <- training_avg_Values1[i]
test[test$Label == 0,][i][test[test$Label == 1,i] == 0] <- training_avg_Values0[i]
}
test[test$Label == 1,][i][test[test$Label == 1,][i] == 0] <- training_avg_Values1[i]
test[test$Label == 0,][i][test[test$Label == 1,][i] == 0] <- training_avg_Values0[i]
test[test$Label == 0,][i][test[test$Label == 0,][i] == 0] <- training_avg_Values0[i]
test[test$Label == 1,][i][test[test$Label == 1,][i] == 0] <- training_avg_Values1[i]
test[test$Label == 0,][i][test[test$Label == 0,][i] == 0] <- training_avg_Values0[i]
}
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
test
train
test
training_avg_Values1 = colMeans(train[train$Label == 1,] , na.rm = TRUE)
training_avg_values0
test
source("Pruning.R")
training_avg_values0
training_avg_values1
training_avg_Values1
training_avg_Values0
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("Pruning.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
minsplit_list
accuracy_list
source("MinSplit.R")
accuracy_list
accuracy_list
source("MinSplit.R")
accuracy_list
which.max(accuracy_list)
source("minSpit.R")
source("MinSpit.R")
source("MinSplit.R")
library("party")
library("rpart")
source("config.R")
source("missing_attributes.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
minsplit_list = seq(1 , 200 , 1)
accuracy_list = numeric(length(minsplit_list))
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
source("missing_attributes.R")
for (j in 1:length(minsplit_list)){
#Making a decision tree with different values of minsplit parameter
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(minsplit = minsplit_list[j] , cp = 0 ))
prediction = predict(decision_tree , test , type = "class")
actual = test[[9]]
TP = length(which(prediction == 1 & actual == 1))
FP = length(which(prediction == 1 & actual == 0))
FN = length(which(prediction == 0 & actual == 1))
TN = length(which(prediction == 0 & actual == 0))
P = TP + FN
N = FP + TN
accuracy_list[j] <- (TP + TN )/(P+N)
}
#plot(minsplit_list , accuracy_list)
best_split = minsplit_list(which.max(accuracy_list))
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(minsplit = best_split , cp = 0 ))
source("compute.R")
}
#Overall Results
print(paste("{\bf I =", Impurity_Function , ", MATr =", Missing_Attribute_Train , ", MATe =", Missing_Attribute_Test , " } & {\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
source("MinSplit.R")
?rpart
source("MinSplit.R")
seq(1 , 200 , 5)
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
