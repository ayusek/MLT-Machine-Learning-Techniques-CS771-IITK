formals(sum)
log(exp(1))
e = exp(1)
log(e)
log(4,2)
log(0,2)
log(-1)
log(2) + log(4)
log(8)
log(8) == log(2) + log(4)
log(4)
log(2)
2*log(2)
log(2,4)
a <- matrix(1:4,2,2)
solve(a)
solve(a) %*% a
b = 3
b = 4
b = 5
summary(mean)
str(mean)
list(1,"a")
a <- list(1,"a")
str(a)
str(str)
str(lm)
m <- matrix(1:100 , 10 , 10)
str(m)
summary(m)
m <- matrix(1:100 , 5 , 20)
summary(m)
library(datasets)
rpois(exp(1))
rpois(1,exp(1))
rpois(2,exp(1))
exp(1)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(2,2)
rpois(1,exp(1))
rpois(1,exp(1))
rpois(1,exp(1))
rpois(1,exp(1))
rpois(1,exp(1))
rpois(1,exp(1))
rpois(1,exp(1))
rpois(1,exp(1))
dnorm(2)
dnorm(3)
dnorm(4)
dnorm(10)
dnorm(0)
dnorm(-2)
pnorm(10)
pnorm(5)
set.seed(1)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)
rnorm(5)
set.seed(!)
set.seed(1)
rnorm(5)
rpois(5,2)
set.seed(1)
rnorm(5)
rpois(5,2)
set.seed(10)
x< - rnorm(100)
x <- rnorm(100)
e <- rnorm(100,2)
e <- rnorm(100 , 0 , 2 )
y  <- 0.5 + 2*x + e
plot(x,y)
plot(x,y)
plot(x,y)
plot(x,y)
plot(x,y)
rbinom(100 , 1 , 0.7)
log.mu <- 5
mu
exp(log.mu)
Always set the seed
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10 , 4)
sample(1:10)
sample(1:10)
sample(1:10)
sample(1:10)
system.time(log(10))
square(3)
system.time(readline("http://www.google.com"))
str(system.time)
?system.time
proc.time
proc.time()
proc.time()
proc.time()
proc.time()
proc.time()
proc.time()
proc.time()
proc.time()
a = 2
a
print a
print"a"
print(a)
install.packages("gbm")
install.packages("gbm")
install.packages("gbm")
swirl()
swirl
?mean
2:3
a <- data.frame(1:3,c(NA,4,NA),c(4,5,6))
a
ind<- which(is.na(a),arr.ind = TRUE)
a[ind] <- rowmeans(df , na.rm = TRUE)[ind[,1]]
a[ind] <- rowMeans(df , na.rm = TRUE)[ind[,1]]
a[ind] <- rowMeans(a , na.rm = TRUE)[ind[,1]]
a
a[1,3] <- NA
a[1,1] <- NA
a[ind] <- rowMeans(a , na.rm = TRUE)[ind[,1]]
a
ind<- which(is.na(a),arr.ind = TRUE)
a[ind] <- rowMeans(a , na.rm = TRUE)[ind[,1]]
a
a <- data.frame(1:3,c(NA,4,NA),c(4,5,6))
a
a[2,2] <- NA
a[3,2] <- 5
a[1,2] <- 1
a[2,2] <- 3
unlist([1 2 3])
unlist([1 ,  2  ,3])
unlist(c(1,2,3))
c(1,2,3)
unlist?
unlist(c(1,2,c(3,4)))
c(1,2,c(3,4))
help(unlist)
unlist(c(1,c(2,3),c(3,4)))
c(1,c(2,3),c(3,4))
a = c(1,c(2,3),c(3,4))
l1 <- list(a = "a", b = 2, c = pi+2i)
l1
unlist(l1)
1+2i * 2
(1+2i )* (2 + 3i)
"a" + "b"
"a"."b"
"a""b"
paste("a" , "b")
paste("apple" , "mango")
paste("apple" , "mango" , sep=NULL)
paste("apple" , "mango" , sep = "")
q()
swirl
swirl()
library("swirl")
swirl()
5+7
x <- 5 + 7
x
y <- x - 3
y
c( 'x' , 1)
z <- c(1.1 , 9 , 3.14)
?c
z
c(z,555,z)
z*2 + 100
my_sqrt = sqrt(z-1)
my_sqrt <- sqrt(z-1)
my_sqrt
my_div = z/my_sqrt
my_div <-  z/my_sqrt
my_div
c(1 , 2 , 3 , 4) + c(0 , 10)
c(1,2,3,4) + c(0,10, 100)
z*2 + 1000
my_div
1:20
pi:10
15:1
?':'
seq(1,20)
seq(0,10 , by = 0.5)
seq(5,10, length = 30 )
my_seq = seq(5,10,length=30)
my_seq <- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along = my_seq)
seq_along(my_seq)
rep(0 , times = 40 )
rep(c(0, 1, 2), times = 10)
rep(c(0,1,2) , each = 10)
c(0.5 , 55 , -10 , 6)
num_vect <- c(0.5 , 55 , -10 , 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My" , "name" , "is")
my_char
paster(my_char , colapse = " ")
paste(my_char , colapse = " ")
paste(my_char)
paste(my_char , collapse = " ")
c(my_char , "Ayush")
my_name <- c(my_char , "Ayush")
my_name
paste(my_name , collapse = " ")
paste("Hello" , "world!" , sep = " ")
paste(1:3 , c('X' ,'Y' ,'Z'))
paste(1:3 , c('X' ,'Y' ,'Z') , sep="")
paste(LETTERS, 1:4, sep = "-")
library("swirl")
swirl()
quit()
sample(0:1,1)
sample(0:1,1)
sample(0:1,1)
sample(0:1,1)
sample just takes a sample from the data
library(UsingR)
install.packages("UsingR")
data(father.son)
qnorm(0.975)
qnorm?
q(0)
?qnorm
pnorm(1)
pnorm(-1)
qnorm(0.95)
qnorm(0.95)*75 + 1100
qnorm(0.95)*7.5 + 1100
1/32(6)
6/32
qnorm(-1)
pnorm(-1)
rpois
pois
ppois(10,5)
ppois(10,15)
library("party")
library("rpart")
library("caret")
setwd('/Users/ayusek/Desktop/Academics/MLT/MLT-Machine-Learning-Techniques-CS771-IITK/Assignment1') #Need to be changed accordingly
source("config.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0 , 0.025 , 0.001)
average_accuracy = numeric(length(cv_list))
#for (j in 1:length(cv_list)){
average_accuracy = numeric(length(cp_list))
#for (j in 1:length(cv_list)){
#   accuracy = 0
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
source("missing_attributes.R")
fit <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = 0 , minsplit = 1))
#printcp(decision_tree)
#plotcp(fit)  #To isualise the error with respect to cp
#decision_tree <- prune(fit , cp = cp_list[j])
decision_tree<- prune(fit, cp=   fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#post(decision_tree , file="tree.ps" , use.n = FALSE , pretty = TRUE ,  title="Classification Tree for Predicting Diabetes", horizontal = FALSE)
source("compute.R") #Added computations to another file to avaoid confusion
}
average_accuracy[j] <- accuracy/5
#average_accuracy[j] <- accuracy/5
#}
#Overall Results
print(paste("{\bf I =", Impurity_Function , ", MATr =", Missing_Attribute_Train , ", MATe =", Missing_Attribute_Test , " } & {\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
test
library("party")
library("rpart")
library("caret")
setwd('/Users/ayusek/Desktop/Academics/MLT/MLT-Machine-Learning-Techniques-CS771-IITK/Assignment1') #Need to be changed accordingly
source("config.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
minsplit_list = seq(1 , 200 , 5) #with a veriation of 5
accuracy_list = numeric(length(minsplit_list))
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
source("missing_attributes.R")
for (j in 1:length(minsplit_list)){
#Making a decision tree with different values of minsplit parameter
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(minsplit = minsplit_list[j] , cp = 0 ))
prediction = predict(decision_tree , test , type = "class")
actual = test[[9]]
TP = length(which(prediction == 1 & actual == 1))
FP = length(which(prediction == 1 & actual == 0))
FN = length(which(prediction == 0 & actual == 1))
TN = length(which(prediction == 0 & actual == 0))
P = TP + FN
N = FP + TN
accuracy_list[j] <- (TP + TN )/(P+N)
}
#plot(minsplit_list , accuracy_list)
best_split = minsplit_list[which.max(accuracy_list)]
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(minsplit = best_split , cp = 0 ))
source("compute.R")
}
#Overall Results
print(paste("{\bf I =", Impurity_Function , ", MATr =", Missing_Attribute_Train , ", MATe =", Missing_Attribute_Test , " } & {\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
library("party")
library("rpart")
library("caret")
setwd('/Users/ayusek/Desktop/Academics/MLT/MLT-Machine-Learning-Techniques-CS771-IITK/Assignment1') #Need to be changed accordingly
source("config.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0.001 , 0.2 , 0.0005) #with a veriation of 0.0005
accuracy_list = numeric(length(cp_list))
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
source("missing_attributes.R")
for (j in 1:length(cp_list)){
#Making a decision tree with different values of minsplit parameter
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(cp = cp_list[j] , minsplit = 1 ))
prediction = predict(decision_tree , test , type = "class")
actual = test[[9]]
TP = length(which(prediction == 1 & actual == 1))
FP = length(which(prediction == 1 & actual == 0))
FN = length(which(prediction == 0 & actual == 1))
TN = length(which(prediction == 0 & actual == 0))
P = TP + FN
N = FP + TN
accuracy_list[j] <- (TP + TN )/(P+N)
}
#plot(cp_list , accuracy_list)
best_cp = cp_list[which.max(accuracy_list)]
decision_tree <- rpart(Label ~ . , data=train , method="class" ,parms = list(split = Impurity_Function) , control =rpart.control(minsplit = 1 , cp = best_cp ))
source("compute.R")
}
#Overall Results
print(paste("{\bf I =", Impurity_Function , ", MATr =", Missing_Attribute_Train , ", MATe =", Missing_Attribute_Test , " } & {\bf",format(round(accuracy/5,3),3),"}" ,"&" ,"{\bf",  format(round(precision/5,3),3) ,"}", "&", "{\bf",format(round(recall/5,3),3),"}" ,"&" , "{\bf",format(round(TP_Rate/5,3),3),"}" ,"&","{\bf", format(round(FP_Rate/5,3),3),"}" ,"&","{\bf", format(round(F1/5,3),3),"}"))
test
training_avg_Values = colMeans(train , na.rm = TRUE)
for (i in 2:8){
#Replace test missing data with train data means
test[i][test[i] == 0] <- training_avg_Values[i]
}
test
test
training_avg_Values = colMeans(train , na.rm = TRUE)
training_avg_Values
for (i in 2:8){
#Replace test missing data with train data means
test[i][test[i] == NA] <- training_avg_Values[i]
}
test
test(which = NA) <- 0
source("config.R")
rows = length(mydata[[1]])
flds <- createFolds(1:rows, k = 5, list = TRUE, returnTrain = FALSE)
#print(paste("{\bf","Data" ,"}", "&" ,"{\bf",  "accuracy","}" ,"&" ,"{\bf",  "precision" ,"}", "&","{\bf", "recall" ,"}","&" ,"{\bf", "TP Rate" ,"}","&", "{\bf","FP Rate" ,"}","&", "{\bf","F1 Score","}"))
cp_list = seq(0.001 , 0.2 , 0.0005) #with a veriation of 0.0005
accuracy_list = numeric(length(cp_list))
for (i in 1:5){
test = mydata[flds[[i]] , ]
train = mydata[setdiff(1:rows , flds[[i]]) ,  ]
test
}
test
training_avg_Values = colMeans(train , na.rm = TRUE)
for (i in 2:8){
#Replace test missing data with train data means
test[i][test[i] == 0] <- training_avg_Values[i]
}
test
source("pruning.R")
source("pruning.R")
source("pruning.R")
source("pruning.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("MinSplit.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
source("Decrease.R")
